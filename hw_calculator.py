#!/usr/bin/env python3
"""
Interaktivn√≠ kalkul√°tor HW po≈æadavk≈Ø pro MyCoder
"""

def hw_calculator():
    print("üßÆ MyCoder HW KALKUL√ÅTOR")
    print("=" * 50)
    
    try:
        # Get user's hardware
        print("Zadej sv≈Øj hardware:")
        ram_gb = int(input("üíæ RAM v GB (nap≈ô. 16): "))
        cpu_cores = int(input("üß† CPU cores (nap≈ô. 8): "))
        has_gpu = input("üéÆ M√°≈° GPU? (y/n): ").lower().startswith('y')
        
        if has_gpu:
            gpu_vram = int(input("üìä GPU VRAM v GB (nap≈ô. 8): "))
        else:
            gpu_vram = 0
            
        disk_gb = int(input("üíø Voln√Ω disk prostor v GB (nap≈ô. 50): "))
        
        print("\n" + "="*50)
        print(f"üìã TV≈ÆJ HARDWARE:")
        print(f"   RAM: {ram_gb} GB")
        print(f"   CPU: {cpu_cores} cores") 
        print(f"   GPU: {'Ano' if has_gpu else 'Ne'}{f' ({gpu_vram}GB VRAM)' if has_gpu else ''}")
        print(f"   Disk: {disk_gb} GB voln√Ωch")
        
        # Analyze what's possible
        print("\nüéØ ANAL√ùZA MO≈ΩNOST√ç:")
        
        models = [
            {
                "name": "tinyllama",
                "size_gb": 0.637,
                "ram_needed": 3,
                "vram_min": 0,
                "disk": 1,
                "quality": "‚≠ê‚≠ê‚òÜ‚òÜ‚òÜ",
                "description": "Z√°kladn√≠ testing"
            },
            {
                "name": "deepseek-coder-1.3b", 
                "size_gb": 0.75,
                "ram_needed": 4,
                "vram_min": 2,
                "disk": 1,
                "quality": "‚≠ê‚≠ê‚≠ê‚òÜ‚òÜ",
                "description": "Mal√Ω k√≥dov√Ω asistent"
            },
            {
                "name": "llama3.2-3b",
                "size_gb": 2,
                "ram_needed": 7,
                "vram_min": 4,
                "disk": 3,
                "quality": "‚≠ê‚≠ê‚≠ê‚≠ê‚òÜ", 
                "description": "Skvƒõl√Ω kompromis"
            },
            {
                "name": "codellama-7b",
                "size_gb": 3.8,
                "ram_needed": 10,
                "vram_min": 8,
                "disk": 5,
                "quality": "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê",
                "description": "V√Ωborn√© k√≥dov√°n√≠"
            },
            {
                "name": "codestral-22b",
                "size_gb": 13,
                "ram_needed": 26,
                "vram_min": 16,
                "disk": 15,
                "quality": "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê",
                "description": "Premium k√≥dov√°n√≠"
            }
        ]
        
        print("   Model                RAM OK  GPU OK  Disk OK  Kvalita     Doporuƒçen√≠")
        print("   " + "="*75)
        
        best_models = []
        
        for model in models:
            ram_ok = ram_gb >= model["ram_needed"]
            gpu_ok = (not has_gpu and model["vram_min"] == 0) or (gpu_vram >= model["vram_min"])
            disk_ok = disk_gb >= model["disk"]
            
            ram_icon = "‚úÖ" if ram_ok else "‚ùå"
            gpu_icon = "‚úÖ" if gpu_ok else ("‚ö†Ô∏è" if model["vram_min"] <= 4 else "‚ùå")
            disk_icon = "‚úÖ" if disk_ok else "‚ùå"
            
            overall_ok = ram_ok and (gpu_ok or not has_gpu or model["vram_min"] == 0) and disk_ok
            
            if overall_ok:
                best_models.append(model)
                recommendation = "üëç FUNGUJE"
            elif ram_ok and disk_ok:
                recommendation = "‚ö†Ô∏è  Pomal√© (bez GPU)"
            else:
                recommendation = "‚ùå Nedoporuƒçeno"
            
            print(f"   {model['name']:<18} {ram_icon}      {gpu_icon}      {disk_icon}      {model['quality']:<11} {recommendation}")
        
        # Best recommendation
        print(f"\nüèÜ NEJLEP≈†√ç VOLBA PRO TV≈ÆJ HW:")
        if best_models:
            best = max(best_models, key=lambda x: x["size_gb"])
            print(f"   üéØ {best['name']}")
            print(f"   üìä {best['description']}")
            print(f"   üíæ Zabere {best['size_gb']} GB + overhead")
            print(f"   üöÄ Kvalita: {best['quality']}")
        else:
            print("   ‚ö†Ô∏è  ≈Ω√°dn√Ω model nevyhovuje tv√©mu HW")
            print("   üí° Doporuƒçuji upgrade RAM nebo pou≈æij cloud")
        
        # Docker recommendation
        print(f"\nüê≥ DOCKER DOPORUƒåEN√ç:")
        if ram_gb >= 32:
            docker_scenario = "Premium (Codestral mo≈æn√Ω)"
            docker_size = "18 GB"
        elif ram_gb >= 16:
            docker_scenario = "Balanced (CodeLlama)"  
            docker_size = "5 GB"
        elif ram_gb >= 8:
            docker_scenario = "Lightweight (DeepSeek)"
            docker_size = "3 GB"
        else:
            docker_scenario = "Minimum (TinyLlama)"
            docker_size = "1 GB"
        
        print(f"   üì¶ Sc√©n√°≈ô: {docker_scenario}")
        print(f"   üíø Docker velikost: {docker_size}")
        
        # Installation command
        print(f"\nüöÄ INSTALAƒåN√ç P≈ò√çKAZ:")
        if ram_gb >= 16:
            print("   ./docker-build.sh full")
        else:
            print("   ./docker-build.sh quick")
        print("   docker-compose up")
        
        # Performance estimate
        print(f"\n‚ö° OƒåEK√ÅVAN√ù V√ùKON:")
        if has_gpu and gpu_vram >= 8:
            performance = "Velmi rychl√Ω (50-200 tokens/sec)"
        elif has_gpu and gpu_vram >= 4:
            performance = "Rychl√Ω (30-100 tokens/sec)"
        elif cpu_cores >= 8:
            performance = "St≈ôedn√≠ (10-30 tokens/sec)"
        elif cpu_cores >= 4:
            performance = "Pomal√Ω (5-15 tokens/sec)"
        else:
            performance = "Velmi pomal√Ω (2-8 tokens/sec)"
            
        print(f"   üìà {performance}")
        
        # Upgrade suggestions
        if ram_gb < 32:
            print(f"\nüí° N√ÅVRHY NA UPGRADE:")
            if ram_gb < 16:
                print(f"   üî¥ KRITICK√ù: Upgrade na 16GB RAM (+{16-ram_gb}GB)")
            elif ram_gb < 32:
                print(f"   üü° DOPORUƒåENO: Upgrade na 32GB RAM (+{32-ram_gb}GB)")
            
            if not has_gpu:
                print("   üéÆ GPU: RTX 3060/4060 (8GB) dramaticky zrychl√≠")
            elif gpu_vram < 8:
                print(f"   üéÆ GPU upgrade: Na 8GB+ VRAM (+{8-gpu_vram}GB)")
                
    except ValueError:
        print("‚ùå Neplatn√Ω vstup. Zadej ƒç√≠sla.")
    except KeyboardInterrupt:
        print("\nüëã Ukonƒçeno u≈æivatelem")

if __name__ == "__main__":
    hw_calculator()