"""
Enhanced MyCoder v2.2.0 with Multi-API Architecture

This module provides the enhanced MyCoder class that integrates the new multi-API
provider system with FEI-inspired architecture patterns for optimal performance
and intelligent fallbacks across different AI providers.

Features:
- 7-tier API provider system (Claude Anthropic, Claude OAuth, Gemini, Mercury, Ollama Local, Termux Ollama, Ollama Remote)
- FEI-inspired tool registry and service layer architecture
- Intelligent provider selection based on context and thermal conditions
- Advanced error recovery with provider fallbacks
- Thermal-aware operation for Q9550 systems
- Session persistence across provider transitions
"""

import logging
import os
import shlex
import socket
import time
import urllib.parse
from dataclasses import asdict, is_dataclass
from pathlib import Path
from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Union

if TYPE_CHECKING:
    pass

try:
    from .adaptive_modes import AdaptiveModeManager, OperationalMode
    from .api_providers import (
        APIProviderConfig,
        APIProviderRouter,
        APIProviderType,
        APIResponse,
        ClaudeAnthropicProvider,
        ClaudeOAuthProvider,
        GeminiProvider,
        OllamaProvider,
    )
    from .mcp_bridge import MCPBridge
    from .tool_registry import (
        ToolExecutionContext,
        get_tool_registry,
    )
    from .context_manager import ContextManager
    from .storage import StorageManager
    from .security import FileSecurityManager, SecurityError
except ImportError:
    from adaptive_modes import AdaptiveModeManager, OperationalMode  # type: ignore
    from mcp_bridge import MCPBridge  # type: ignore
    from context_manager import ContextManager
    from storage import StorageManager
    from security import FileSecurityManager, SecurityError

    from mycoder.api_providers import (  # type: ignore
        APIProviderConfig,
        APIProviderRouter,
        APIProviderType,
        APIResponse,
        ClaudeAnthropicProvider,
        ClaudeOAuthProvider,
        GeminiProvider,
        OllamaProvider,
    )
    from mycoder.tool_registry import (  # type: ignore
        ToolExecutionContext,
        get_tool_registry,
    )

logger = logging.getLogger(__name__)

SYSTEM_PROMPT = """You are MyCoder, an AI development assistant.

CRITICAL: When editing files, you MUST use the /edit command with Search & Replace pattern.

## File Operations

### Reading Files
/read <path>

### Editing Files (Search & Replace)
/edit <path> "old_string" "new_string"
- old_string: EXACT text to find (must be unique in file)
- new_string: New text to replace with
- ALWAYS read file first with /read
- NEVER write entire file content
- Use /edit --all to replace all occurrences

### Writing New Files
/write <path>
[content on next lines]

## Examples

WRONG (generates entire file):
User: "Add a print statement to hello.py"
Assistant: "Here's the updated file:
def hello():
    print('Starting')
    return 'Hi'
..."

CORRECT (Search & Replace):
User: "Add a print statement to hello.py"
Assistant: "I'll add a print statement:
/read hello.py
/edit hello.py \"def hello():\" \"def hello():\\n    print('Starting')\"

## Rules
1. ALWAYS use /edit for modifications, NEVER write full files
2. Make old_string unique (include surrounding context)
3. Read file first to verify old_string exists
4. If old_string not unique, add more context
"""


class EnhancedMyCoderV2:
    """
    Enhanced MyCoder v2.2.0 with Multi-API Architecture

    Provides intelligent AI-powered development assistance with:
    - 7-tier API provider fallback system
    - FEI-inspired tool registry and service layers
    - Thermal-aware operation for Q9550 systems
    - Advanced session management across providers
    - Intelligent context-aware provider selection
    """

    def __init__(
        self,
        working_directory: Optional[Path] = None,
        config: Optional[Dict[str, Any]] = None,
    ):
        """
        Initialize Enhanced MyCoder v2.2.0

        Args:
            working_directory: Base directory for operations
            config: Configuration dictionary for API providers and settings
        """
        self.working_directory = (working_directory or Path.cwd()).resolve()

        # Initialize Core Managers
        self.context_manager = ContextManager(self.working_directory)
        self.storage_manager = StorageManager(self.working_directory)
        self.security_manager = FileSecurityManager(self.working_directory)

        # Load Config/Context
        context_data = self.context_manager.get_context()
        self.system_prompt_context = context_data.system_prompt

        # Use provided config override or loaded config
        loaded_config = context_data.config
        if config:
            if is_dataclass(config):
                config = asdict(config)
            # Merge provided config on top of loaded
            loaded_config.update(config)

        self.config = loaded_config

        self.session_store: Dict[str, Dict] = {}
        self.thermal_monitor = None
        self._initialized = False

        # History is now managed by StorageManager, but we keep a local buffer for current run compatibility
        self.history = []

        # Initialize API provider router
        self.provider_router = None

        # Initialize tool registry
        self.tool_registry = get_tool_registry()

        # Initialize MCP bridge and tool orchestrator (v2.2.0)
        self.mcp_bridge = None
        self.tool_orchestrator = None

        # Initialize adaptive mode manager
        claude_oauth_enabled = bool(
            self._get_section("claude_oauth").get("enabled", False)
        )
        self.mode_manager = AdaptiveModeManager(
            OperationalMode.FULL, claude_auth_enabled=claude_oauth_enabled
        )

        logger.info(
            f"Enhanced MyCoder v2.2.0 initialized with working directory: {self.working_directory}"
        )

    def _load_history(self) -> List[Dict[str, Any]]:
        """Deprecated: History is loaded via StorageManager on demand."""
        return []

    @property
    def session(self) -> Dict[str, Dict]:
        return self.session_store

    @session.setter
    def session(self, value: Dict[str, Dict]) -> None:
        self.session_store = value

    @property
    def provider(self):
        return self.provider_router

    @provider.setter
    def provider(self, value) -> None:
        self.provider_router = value

    @property
    def tool(self):
        return self.tool_registry

    @tool.setter
    def tool(self, value) -> None:
        self.tool_registry = value

    def _save_history(self):
        """Deprecated: History is saved via StorageManager transactionally."""

    async def initialize(self):
        """Initialize Enhanced MyCoder system with multi-API providers"""
        if self._initialized:
            logger.debug("Enhanced MyCoder already initialized")
            return

        logger.info("Initializing Enhanced MyCoder v2.2.0 with multi-API system...")

        # Initialize storage
        await self.storage_manager.connect()

        if hasattr(self.tool_registry, "reset"):
            self.tool_registry.reset()

        # Initialize API providers
        await self._initialize_api_providers()

        # NEW (v2.2.0): Initialize MCP bridge and tool orchestrator
        await self._initialize_tool_system()

        # Initialize thermal monitoring for Q9550 systems
        await self._initialize_thermal_monitoring()

        # Start adaptive mode monitoring
        await self.mode_manager.start_monitoring()
        await self.mode_manager.evaluate_and_adapt()

        # Register additional tools
        await self._register_enhanced_tools()

        self._initialized = True
        logger.info("Enhanced MyCoder v2.2.0 initialization complete")

        # Log available providers
        available_providers = self.provider_router.get_available_providers()
        logger.info(
            f"Available API providers: {[p.value for p in available_providers]}"
        )

    async def _initialize_api_providers(self):
        """Initialize the multi-API provider system"""
        provider_configs = []

        claude_config = self._get_section("claude_anthropic")
        claude_enabled = claude_config.get(
            "enabled", self.config.get("claude_anthropic_enabled", True)
        )
        claude_timeout = claude_config.get(
            "timeout_seconds", self.config.get("claude_timeout_seconds", 30)
        )
        claude_max_retries = claude_config.get("max_retries", 3)
        claude_model = claude_config.get(
            "model", self.config.get("claude_model", "claude-3-5-sonnet-20241022")
        )
        claude_base_url = claude_config.get("base_url")
        claude_api_key = claude_config.get("api_key") or os.getenv("ANTHROPIC_API_KEY")

        # Claude Anthropic API (Priority 1)
        if bool(claude_enabled):
            claude_provider_config = APIProviderConfig(
                provider_type=APIProviderType.CLAUDE_ANTHROPIC,
                enabled=True,
                timeout_seconds=claude_timeout,
                max_retries=claude_max_retries,
                config={
                    "api_key": claude_api_key,
                    "model": claude_model,
                    "base_url": claude_base_url,
                },
            )
            provider_configs.append(claude_provider_config)

        # Claude OAuth (Priority 2)
        claude_oauth_config = self._get_section("claude_oauth")
        claude_oauth_enabled = claude_oauth_config.get(
            "enabled", self.config.get("claude_oauth_enabled", False)
        )
        claude_oauth_timeout = claude_oauth_config.get(
            "timeout_seconds", self.config.get("claude_oauth_timeout_seconds", 45)
        )
        claude_oauth_max_retries = claude_oauth_config.get("max_retries", 3)
        if bool(claude_oauth_enabled):
            oauth_config = APIProviderConfig(
                provider_type=APIProviderType.CLAUDE_OAUTH,
                enabled=True,  # Always try OAuth as fallback
                timeout_seconds=claude_oauth_timeout,
                max_retries=claude_oauth_max_retries,
                config={},
            )
            provider_configs.append(oauth_config)

        # Gemini API (Priority 3)
        gemini_config = self._get_section("gemini")
        gemini_enabled = gemini_config.get(
            "enabled", self.config.get("gemini_enabled", True)
        )
        gemini_timeout = gemini_config.get(
            "timeout_seconds", self.config.get("gemini_timeout_seconds", 30)
        )
        gemini_max_retries = gemini_config.get("max_retries", 3)
        gemini_model = gemini_config.get(
            "model", self.config.get("gemini_model", "gemini-1.5-pro")
        )
        gemini_api_key = gemini_config.get("api_key") or os.getenv("GEMINI_API_KEY")
        if bool(gemini_enabled):
            gemini_provider_config = APIProviderConfig(
                provider_type=APIProviderType.GEMINI,
                enabled=True,
                timeout_seconds=gemini_timeout,
                max_retries=gemini_max_retries,
                config={
                    "api_key": gemini_api_key,
                    "model": gemini_model,
                },
            )
            provider_configs.append(gemini_provider_config)

        # Mercury Diffusion LLM (Priority 4)
        mercury_config = self._get_section("inception_mercury")
        mercury_enabled = mercury_config.get(
            "enabled", self.config.get("inception_mercury_enabled", False)
        )

        if mercury_enabled:
            mercury_provider_config = APIProviderConfig(
                provider_type=APIProviderType.MERCURY,
                enabled=True,
                timeout_seconds=mercury_config.get(
                    "timeout_seconds",
                    self.config.get("inception_mercury_timeout_seconds", 60),
                ),
                config={
                    "api_key": mercury_config.get("api_key")
                    or os.getenv("INCEPTION_API_KEY"),
                    "base_url": mercury_config.get(
                        "base_url",
                        self.config.get(
                            "inception_mercury_base_url",
                            "https://api.inceptionlabs.ai/v1",
                        ),
                    ),
                    "model": mercury_config.get(
                        "model", self.config.get("inception_mercury_model", "mercury")
                    ),
                    "realtime": mercury_config.get(
                        "realtime", self.config.get("inception_mercury_realtime", False)
                    ),
                    "diffusing": mercury_config.get(
                        "diffusing",
                        self.config.get("inception_mercury_diffusing", False),
                    ),
                },
            )
            provider_configs.append(mercury_provider_config)

        # Ollama Local (Priority 4)
        ollama_local_config = self._get_section("ollama_local")
        ollama_local_enabled = ollama_local_config.get(
            "enabled", self.config.get("ollama_local_enabled", True)
        )
        ollama_local_timeout = ollama_local_config.get(
            "timeout_seconds", self.config.get("ollama_local_timeout_seconds", 60)
        )
        ollama_local_max_retries = ollama_local_config.get("max_retries", 2)
        ollama_local_url = (
            ollama_local_config.get("base_url")
            or self.config.get("ollama_local_base_url")
            or self.config.get("ollama_local_url", "http://localhost:11434")
        )
        ollama_local_model = ollama_local_config.get(
            "model", self.config.get("ollama_local_model", "tinyllama")
        )
        if bool(ollama_local_enabled):
            local_ollama_config = APIProviderConfig(
                provider_type=APIProviderType.OLLAMA_LOCAL,
                enabled=True,
                timeout_seconds=ollama_local_timeout,  # Longer timeout for local processing
                max_retries=ollama_local_max_retries,
                config={
                    "base_url": ollama_local_url,
                    "model": ollama_local_model,
                },
            )
            provider_configs.append(local_ollama_config)

        # Termux Ollama (Priority 5)
        termux_config = self._get_section("termux_ollama")
        termux_enabled = termux_config.get(
            "enabled", self.config.get("termux_ollama_enabled", False)
        )
        if bool(termux_enabled):
            termux_provider_config = APIProviderConfig(
                provider_type=APIProviderType.TERMUX_OLLAMA,
                enabled=True,
                timeout_seconds=termux_config.get("timeout_seconds", 45),
                max_retries=termux_config.get("max_retries", 2),
                config={
                    "base_url": termux_config.get(
                        "base_url", "http://192.168.1.100:11434"
                    ),
                    "model": termux_config.get("model", "tinyllama"),
                    "connection_type": termux_config.get("connection_type", "wifi"),
                },
            )
            provider_configs.append(termux_provider_config)

        # Ollama Remote (Priority 5)
        remote_urls = self.config.get("ollama_remote_urls", [])
        remote_model = self.config.get("ollama_remote_model", "tinyllama")
        for i, url in enumerate(remote_urls):
            remote_config = APIProviderConfig(
                provider_type=APIProviderType.OLLAMA_REMOTE,
                enabled=True,
                timeout_seconds=45,
                config={
                    "base_url": url,
                    "model": remote_model,
                },
            )
            provider_configs.append(remote_config)

        # Initialize router with all providers
        self.provider_router = APIProviderRouter(provider_configs)

        logger.info(f"Initialized {len(provider_configs)} API providers")

    async def _initialize_tool_system(self):
        """Initialize MCP bridge and tool orchestrator for action-performing CLI (v2.2.0)"""
        try:
            logger.info("Initializing tool system (MCP bridge + orchestrator)...")

            # Initialize MCP bridge
            mcp_config = self._get_section("mcp")
            mcp_url = mcp_config.get(
                "url", self.config.get("mcp_url", "http://127.0.0.1:8020")
            )
            auto_start = mcp_config.get(
                "auto_start", self.config.get("mcp_auto_start", False)
            )

            self.mcp_bridge = MCPBridge(
                mcp_url=mcp_url,
                auto_start=auto_start,
            )

            # Initialize and start MCP server if needed
            success = await self.mcp_bridge.initialize()

            if not success:
                logger.warning(
                    "MCP bridge initialization failed - tool execution will be limited"
                )
                self.mcp_bridge = None
                self.tool_orchestrator = None
                return

            # Register MCP tools in tool registry
            await self.mcp_bridge.register_mcp_tools_in_registry(self.tool_registry)

            # Initialize tool orchestrator (lazy import to avoid cyclic dependency)
            from .tool_orchestrator import ToolExecutionOrchestrator

            self.tool_orchestrator = ToolExecutionOrchestrator(
                tool_registry=self.tool_registry,
                mcp_bridge=self.mcp_bridge,
                ai_client=self,
            )

            logger.info("Tool system initialized successfully")

        except Exception as e:
            logger.error(f"Error initializing tool system: {e}")
            self.mcp_bridge = None
            self.tool_orchestrator = None

    async def _initialize_thermal_monitoring(self):
        """Initialize thermal monitoring for Q9550 systems"""
        thermal_config = self._get_section("thermal")
        thermal_enabled = thermal_config.get(
            "enabled", self.config.get("thermal_enabled", True)
        )
        thermal_script = thermal_config.get(
            "performance_script",
            os.environ.get("MYCODER_THERMAL_SCRIPT", ""),
        )
        thermal_settings = {
            "enabled": bool(thermal_enabled),
            "max_temp": thermal_config.get(
                "max_temp", self.config.get("thermal_max_temp", 80)
            ),
            "critical_temp": thermal_config.get(
                "critical_temp", self.config.get("thermal_critical_temp", 85)
            ),
            "check_interval": thermal_config.get(
                "check_interval", self.config.get("thermal_check_interval", 30)
            ),
        }

        if not thermal_settings["enabled"]:
            self.thermal_monitor = {"enabled": False}
            return

        try:
            self.thermal_monitor = {
                "enabled": True,
                "script_path": thermal_script,
            }

            if self.provider_router:
                await self.provider_router.configure_thermal_integration(
                    thermal_settings
                )

            # Check if PowerManagement system is available
            import subprocess

            result = subprocess.run(
                [
                    thermal_script,
                    "status",
                ],
                capture_output=True,
                text=True,
                timeout=5,
            )

            if result.returncode == 0:
                logger.info("Thermal monitoring enabled for Q9550 system")
            else:
                logger.info("Thermal monitoring not available")

        except Exception as e:
            logger.warning(f"Failed to initialize thermal monitoring: {e}")
            self.thermal_monitor = {"enabled": True, "script_path": thermal_script}

    async def _register_enhanced_tools(self):
        """Register enhanced tools for v2.2.0 functionality"""
        # Tools are already registered in tool_registry initialization
        # This method can be extended for additional v2.2.0 specific tools

        # Add event handlers for tool monitoring
        def tool_execution_handler(event_type, data):
            logger.debug(
                f"Tool event: {event_type} - {data.get('tool_name', 'unknown')}"
            )

        self.tool_registry.add_event_handler(
            "tool_post_execution", tool_execution_handler
        )
        self.tool_registry.add_event_handler(
            "tool_execution_error", tool_execution_handler
        )

        logger.info("Enhanced tool system configured")

    async def process_request(
        self,
        prompt: str,
        files: Optional[List[Union[str, Path]]] = None,
        session_id: Optional[str] = None,
        continue_session: bool = False,
        preferred_provider: Optional[APIProviderType] = None,
        use_tools: bool = True,
        stream_callback: Optional[Callable[[str], None]] = None,
        **kwargs,
    ) -> Dict[str, Any]:
        """
        Process a development request with multi-API intelligence

        Args:
            prompt: The user's request or question
            files: Files to include in the request context
            session_id: Session ID for conversation continuity
            continue_session: Whether to continue existing session
            preferred_provider: Preferred API provider to try first
            use_tools: Whether to use tool registry for enhanced capabilities
            **kwargs: Additional parameters

        Returns:
            Dict containing response content, metadata, and provider info
        """
        if not self._initialized:
            await self.initialize()

        start_time = time.time()
        current_mode = self.mode_manager.current_mode

        logger.info(f"Processing request in {current_mode.value} mode")
        logger.debug(f"Request: {prompt[:100]}{'...' if len(prompt) > 100 else ''}")

        try:
            # Prepare request context
            context = await self._prepare_enhanced_context(
                prompt=prompt,
                files=files,
                session_id=session_id,
                continue_session=continue_session,
                **kwargs,
            )
            if use_tools:
                context["tool_registry"] = self.tool_registry

            # Get thermal status if monitoring enabled
            if self.thermal_monitor and self.thermal_monitor["enabled"]:
                context["thermal_status"] = await self._get_thermal_status()

            full_prompt = prompt
            if use_tools:
                # Inject AGENTS.md context
                full_prompt = (
                    f"{SYSTEM_PROMPT}\n{self.system_prompt_context}\n\nUser: {prompt}"
                )

            # Execute request with multi-API system
            max_attempts = int(self.config.get("request_retry_attempts", 2))
            if max_attempts < 1:
                max_attempts = 1
            api_response = None
            for attempt in range(1, max_attempts + 1):
                api_response = await self.provider_router.query(
                    prompt=full_prompt,
                    context=context,
                    preferred_provider=preferred_provider,
                    fallback_enabled=self.config.get("fallback_enabled", True),
                    stream_callback=stream_callback,
                    **kwargs,
                )
                if api_response.success or attempt == max_attempts:
                    break
                logger.warning(
                    "Request failed on attempt %s/%s, retrying...",
                    attempt,
                    max_attempts,
                )

            # Enhance response with tool integration if requested
            if use_tools and api_response.success:
                enhanced_response = await self._enhance_with_tools(
                    api_response, context
                )
                if enhanced_response:
                    api_response = enhanced_response

            # Update session store
            if session_id and api_response.success:
                await self._update_enhanced_session_store(
                    session_id, context, api_response
                )

            # Prepare final response
            duration = time.time() - start_time

            response_session_id = api_response.session_id or session_id
            response = {
                "success": api_response.success,
                "content": api_response.content,
                "provider": api_response.provider.value,
                "session_id": response_session_id,
                "cost": api_response.cost,
                "duration_seconds": duration,
                "duration_ms": api_response.duration_ms,
                "tokens_used": api_response.tokens_used,
                "mode": current_mode.value,
                "metadata": api_response.metadata or {},
            }

            if not api_response.success:
                response["error"] = api_response.error
                response["recovery_suggestions"] = self._get_recovery_suggestions()

            # Append to history and save (StorageManager)
            # We save the interaction pair
            metadata = {
                "response_meta": response,
                "session_id": session_id or "default",
            }
            # Save User Prompt
            await self.storage_manager.save_interaction(
                session_id or "default", "user", prompt, metadata
            )
            # Save AI Response
            await self.storage_manager.save_interaction(
                session_id or "default", "ai", api_response.content, metadata
            )

            # Keep local history buffer for UI if needed (though UI handles its own history usually)
            self.history.append(
                {
                    "timestamp": time.time(),
                    "prompt": prompt,
                    "response": response,
                }
            )

            logger.info(
                f"Request completed in {duration:.1f}s using {api_response.provider.value}"
            )
            return response

        except Exception as e:
            logger.error(f"Request processing failed: {e}")

            return {
                "success": False,
                "content": "",
                "provider": "none",
                "error": str(e),
                "mode": current_mode.value,
                "duration_seconds": time.time() - start_time,
                "recovery_suggestions": self._get_recovery_suggestions(),
            }

    async def _prepare_enhanced_context(self, **kwargs) -> Dict[str, Any]:
        """Prepare enhanced request context for multi-API processing"""
        context = {
            "working_directory": self.working_directory,
            "mode": self.mode_manager.current_mode.value,
            "timestamp": time.time(),
        }

        # Add file context
        if kwargs.get("files"):
            context["files"] = [
                Path(f) if isinstance(f, str) else f for f in kwargs["files"]
            ]

        # Add session context
        if kwargs.get("session_id"):
            context["session_id"] = kwargs["session_id"]
            context["continue_session"] = kwargs.get("continue_session", False)

        # Add network status
        context["network_status"] = self._check_network_status()

        # Add resource limits based on mode
        if self.mode_manager.current_mode == OperationalMode.AUTONOMOUS:
            context["resource_limits"] = {
                "max_tokens": 2048,
                "timeout_seconds": 30,
                "thermal_sensitive": True,
            }
        elif self.mode_manager.current_mode == OperationalMode.RECOVERY:
            context["resource_limits"] = {
                "max_tokens": 512,
                "timeout_seconds": 15,
                "thermal_sensitive": True,
            }

        return context

    async def _get_thermal_status(self) -> Dict[str, Any]:
        """Get current thermal status for Q9550 system"""
        try:
            import subprocess

            result = subprocess.run(
                [self.thermal_monitor["script_path"], "status"],
                capture_output=True,
                text=True,
                timeout=5,
            )

            if result.returncode == 0:
                # Parse temperature from output
                output = result.stdout.lower()

                # Extract temperature if available
                cpu_temp = 60  # Default safe assumption
                if "temp" in output:
                    # Try to extract temperature value
                    import re

                    temp_match = re.search(r"(\d+)Â°?c", output)
                    if temp_match:
                        cpu_temp = int(temp_match.group(1))

                status = "normal"
                if cpu_temp > 85:
                    status = "critical"
                elif cpu_temp > 80:
                    status = "high"
                elif cpu_temp > 75:
                    status = "elevated"

                return {
                    "cpu_temp": cpu_temp,
                    "status": status,
                    "safe_operation": cpu_temp < 80,
                    "timestamp": time.time(),
                }

            return {"status": "unknown", "safe_operation": True}

        except Exception as e:
            logger.warning(f"Thermal status check failed: {e}")
            return {"status": "unknown", "safe_operation": True}

    def _get_network_target(self) -> tuple[str, int]:
        """
        Determine the primary network target for connectivity checks.
        Prioritizes explicit overrides, then configured LLM providers.
        """
        override_host = self.config.get("network_check_host")
        if override_host:
            port_value = self.config.get("network_check_port", 11434)
            try:
                return override_host, int(port_value)
            except (TypeError, ValueError):
                return override_host, 11434

        local_config = self._get_section("ollama_local")
        local_enabled = local_config.get(
            "enabled", self.config.get("ollama_local_enabled", True)
        )
        if local_enabled:
            local_url = (
                local_config.get("base_url")
                or self.config.get("ollama_local_base_url")
                or self.config.get("ollama_local_url", "http://localhost:11434")
            )
            parsed = urllib.parse.urlparse(local_url)
            if parsed.hostname:
                port = parsed.port or (443 if parsed.scheme == "https" else 80)
                return parsed.hostname, port

        remote_urls = self.config.get("ollama_remote_urls", [])
        if remote_urls:
            parsed = urllib.parse.urlparse(remote_urls[0])
            if parsed.hostname:
                port = parsed.port or (443 if parsed.scheme == "https" else 80)
                return parsed.hostname, port

        return "1.1.1.1", 53

    def _get_section(self, section_key: str) -> Dict[str, Any]:
        """Return a configuration section as a dict."""
        section = self.config.get(section_key, {})
        if isinstance(section, dict):
            return section
        return {}

    def _check_network_status(
        self, host: Optional[str] = None, port: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        Check network connectivity and quality to target host using TCP.

        Quality categories:
        - excellent: < 20 ms (USB/Local WiFi)
        - good: < 100 ms
        - poor: > 100 ms
        - offline: Host unreachable
        """
        if host is None or port is None:
            host, port = self._get_network_target()

        try:
            start_time = time.time()
            sock = socket.create_connection((host, port), timeout=2.0)
            sock.close()

            latency_ms = (time.time() - start_time) * 1000
            quality = "poor"
            if latency_ms < 20:
                quality = "excellent"
            elif latency_ms < 100:
                quality = "good"

            return {
                "connected": True,
                "quality": quality,
                "latency_ms": round(latency_ms, 2),
                "target": f"{host}:{port}",
                "timestamp": time.time(),
            }

        except (socket.timeout, socket.error, Exception) as e:
            return {
                "connected": False,
                "quality": "offline",
                "latency_ms": 0,
                "target": f"{host}:{port}",
                "timestamp": time.time(),
                "error": str(e),
            }

    async def _enhance_with_tools(
        self, api_response: APIResponse, context: Dict[str, Any]
    ) -> Optional[APIResponse]:
        """Enhance API response using tool registry"""
        try:
            # Create tool execution context
            tool_context = ToolExecutionContext(
                mode=context.get("mode", "FULL"),
                working_directory=context.get("working_directory"),
                session_id=context.get("session_id"),
                thermal_status=context.get("thermal_status"),
                network_status=context.get("network_status"),
                resource_limits=context.get("resource_limits"),
            )

            content = api_response.content
            lines = content.splitlines()
            tool_results = []
            tools_used = []
            tool_metadata = []

            index = 0
            working_dir_value = tool_context.working_directory or self.working_directory
            if isinstance(working_dir_value, Path):
                base_dir = working_dir_value
            elif isinstance(working_dir_value, str):
                base_dir = Path(working_dir_value)
            else:
                base_dir = self.working_directory
            base_dir = base_dir.resolve()

            def _resolve_for_security(relative_path: str) -> Path:
                candidate = Path(relative_path)
                if not candidate.is_absolute():
                    candidate = base_dir / candidate
                return candidate.resolve(strict=False)

            while index < len(lines):
                raw_line = lines[index]
                line = raw_line.strip()

                if line.startswith("/read "):
                    path = line[6:].strip()
                    if not path:
                        tool_results.append("ERR Read failed: missing path")
                        index += 1
                        continue

                    # Security Check
                    try:
                        target_path = _resolve_for_security(path)
                        self.security_manager.validate_path(
                            target_path, extra_allowed_paths=[base_dir]
                        )
                    except SecurityError as e:
                        tool_results.append(f"ERR Security: {e}")
                        index += 1
                        continue

                    result = await self.tool_registry.execute_tool(
                        "file_read",
                        tool_context,
                        path=path,
                    )
                    if result.success:
                        tool_results.append(f"File: {path}\n{result.data}")
                    else:
                        tool_results.append(f"ERR Read failed: {result.error}")
                    tools_used.append("file_read")
                    tool_metadata.append(result.metadata)
                    index += 1
                    continue

                if line.startswith("/edit "):
                    try:
                        parts = shlex.split(line[6:])
                    except ValueError as exc:
                        tool_results.append(f"ERR Edit failed: {exc}")
                        index += 1
                        continue
                    replace_all = "--all" in parts
                    filtered = [part for part in parts if part != "--all"]
                    if len(filtered) < 3:
                        tool_results.append("ERR Edit failed: missing arguments")
                        index += 1
                        continue
                    path, old_str, new_str = filtered[0], filtered[1], filtered[2]

                    # Security Check
                    try:
                        target_path = _resolve_for_security(path)
                        self.security_manager.validate_path(
                            target_path, extra_allowed_paths=[base_dir]
                        )
                    except SecurityError as e:
                        tool_results.append(f"ERR Security: {e}")
                        index += 1
                        continue

                    # Snapshot before edit
                    step_id = f"edit_{int(time.time())}"
                    await self.storage_manager.create_snapshot(step_id, path)

                    result = await self.tool_registry.execute_tool(
                        "file_edit",
                        tool_context,
                        path=path,
                        old_string=old_str,
                        new_string=new_str,
                        replace_all=replace_all,
                    )
                    if result.success:
                        tool_results.append(f"OK Edited {path}: {result.data}")
                    else:
                        tool_results.append(f"ERR Edit failed: {result.error}")
                    tools_used.append("file_edit")
                    tool_metadata.append(result.metadata)
                    index += 1
                    continue

                if line.startswith("/write "):
                    try:
                        parts = shlex.split(line[7:])
                    except ValueError as exc:
                        tool_results.append(f"ERR Write failed: {exc}")
                        index += 1
                        continue
                    if not parts:
                        tool_results.append("ERR Write failed: missing path")
                        index += 1
                        continue
                    path = parts[0]

                    # Security Check
                    try:
                        target_path = _resolve_for_security(path)
                        self.security_manager.validate_path(
                            target_path, extra_allowed_paths=[base_dir]
                        )
                    except SecurityError as e:
                        tool_results.append(f"ERR Security: {e}")
                        # Skip content lines
                        scan_index = index + 1
                        while scan_index < len(lines):
                            next_line = lines[scan_index]
                            next_stripped = next_line.strip()
                            if any(
                                next_stripped.startswith(prefix)
                                for prefix in ("/read ", "/edit ", "/write ")
                            ):
                                break
                            scan_index += 1
                        index = scan_index
                        continue

                    content_lines = []
                    scan_index = index + 1
                    while scan_index < len(lines):
                        next_line = lines[scan_index]
                        next_stripped = next_line.strip()
                        if any(
                            next_stripped.startswith(prefix)
                            for prefix in ("/read ", "/edit ", "/write ")
                        ):
                            break
                        content_lines.append(next_line)
                        scan_index += 1
                    write_content = "\n".join(content_lines)

                    # Snapshot before write
                    step_id = f"write_{int(time.time())}"
                    await self.storage_manager.create_snapshot(step_id, path)

                    result = await self.tool_registry.execute_tool(
                        "file_write",
                        tool_context,
                        path=path,
                        content=write_content,
                    )
                    if result.success:
                        tool_results.append(f"OK Wrote {path}: {result.data}")
                    else:
                        tool_results.append(f"ERR Write failed: {result.error}")
                    tools_used.append("file_write")
                    tool_metadata.append(result.metadata)
                    index = scan_index
                    continue

                index += 1

            if tool_results:
                enhanced_content = (
                    f"{api_response.content}\n\n## Tool Execution Results:\n"
                    + "\n".join(tool_results)
                )
                return APIResponse(
                    success=True,
                    content=enhanced_content,
                    provider=api_response.provider,
                    cost=api_response.cost,
                    duration_ms=api_response.duration_ms,
                    tokens_used=api_response.tokens_used,
                    session_id=api_response.session_id,
                    metadata={
                        **api_response.metadata,
                        "tools_used": tools_used,
                        "tool_results": tool_metadata,
                    },
                )

            lower_content = content.lower()

            # Check for command execution intent (Simulation/Test logic)
            if any(
                key in lower_content
                for key in ["run command:", "execute:", "poetry update"]
            ):
                # In a real scenario, we would parse the command.
                # Here we just detect the intent for testing routing logic.
                cmd_match = (
                    "poetry update"
                    if "poetry update" in lower_content
                    else "unknown command"
                )

                logger.info(f"Detected command execution intent: {cmd_match}")

                # Simulate command execution
                enhanced_content = (
                    f"{api_response.content}\n\nCommand Execution:\n"
                    f"Would execute '{cmd_match}'"
                )

                return APIResponse(
                    success=True,
                    content=enhanced_content,
                    provider=api_response.provider,
                    cost=api_response.cost,
                    duration_ms=api_response.duration_ms + 10,  # Simulate overhead
                    tokens_used=api_response.tokens_used,
                    session_id=api_response.session_id,
                    metadata={
                        **api_response.metadata,
                        "tools_used": ["command_execution"],
                        "tool_results": [{"command": cmd_match, "status": "simulated"}],
                    },
                )

            # Existing file read logic
            if "read file" in lower_content or "show file" in lower_content:
                # Extract file path from content (simplified)
                # In a real implementation, this would use NLP to extract file paths
                file_result = await self.tool_registry.execute_tool(
                    "file_read",
                    tool_context,
                    operation="read",
                    path="example.txt",  # This should be extracted from content
                )

                if file_result.success:
                    # Append file contents to response
                    enhanced_content = (
                        f"{api_response.content}\n\nFile Contents:\n{file_result.data}"
                    )

                    return APIResponse(
                        success=True,
                        content=enhanced_content,
                        provider=api_response.provider,
                        cost=api_response.cost,
                        duration_ms=api_response.duration_ms + file_result.duration_ms,
                        tokens_used=api_response.tokens_used,
                        session_id=api_response.session_id,
                        metadata={
                            **api_response.metadata,
                            "tools_used": ["file_read"],
                            "tool_results": [file_result.metadata],
                        },
                    )

            return None  # No enhancement applied

        except Exception as e:
            logger.error(f"Tool enhancement failed: {e}")
            return None

    async def _update_enhanced_session_store(
        self, session_id: str, context: Dict[str, Any], response: APIResponse
    ):
        """Update session store with enhanced metadata"""
        self.session_store[session_id] = {
            "last_context": context,
            "last_response": {
                "provider": response.provider.value,
                "success": response.success,
                "cost": response.cost,
                "duration_ms": response.duration_ms,
                "tokens_used": response.tokens_used,
            },
            "updated_at": time.time(),
            "mode": context.get("mode"),
            "thermal_status": context.get("thermal_status"),
            "total_interactions": self.session_store.get(session_id, {}).get(
                "total_interactions", 0
            )
            + 1,
        }

        # Cleanup old sessions (keep last 100)
        if len(self.session_store) > 100:
            oldest_sessions = sorted(
                self.session_store.items(), key=lambda x: x[1]["updated_at"]
            )[:-100]
            for session_id, _ in oldest_sessions:
                del self.session_store[session_id]

    def _get_recovery_suggestions(self) -> List[str]:
        """Get recovery suggestions for failed requests"""
        return [
            "Check internet connectivity for cloud providers",
            "Verify API keys are configured (ANTHROPIC_API_KEY, GEMINI_API_KEY)",
            "Ensure Claude CLI is authenticated: claude auth login",
            "Check if Ollama is running: ollama list",
            "Monitor system temperature for Q9550 thermal limits",
            "Try with preferred_provider parameter to force specific provider",
            "Use RECOVERY mode for basic file operations only",
        ]

    async def get_system_status(self) -> Dict[str, Any]:
        """Get comprehensive system status"""
        if not self._initialized:
            return {"status": "not_initialized"}

        # Get provider health
        provider_health = await self.provider_router.health_check_all()

        # Get thermal status
        thermal_status = None
        if self.thermal_monitor and self.thermal_monitor["enabled"]:
            thermal_status = await self._get_thermal_status()

        # Get tool registry stats
        tool_stats = self.tool_registry.get_registry_stats()

        # Get mode manager status
        mode_status = self.mode_manager.get_system_status()

        return {
            "status": "initialized",
            "working_directory": str(self.working_directory),
            "active_sessions": len(self.session_store),
            "providers": provider_health,
            "thermal": thermal_status,
            "tools": tool_stats,
            "mode": mode_status,
            "timestamp": time.time(),
        }

    async def force_provider(self, provider_type: APIProviderType) -> bool:
        """Force a specific provider for testing purposes"""
        try:
            provider = self.provider_router._get_provider(provider_type)
            if provider:
                # Test provider with simple query
                test_response = await provider.query("Hello", timeout_seconds=10)
                return test_response.success
            return False
        except Exception as e:
            logger.error(f"Provider test failed: {e}")
            return False

    async def shutdown(self):
        """Gracefully shutdown Enhanced MyCoder system"""
        logger.info("Shutting down Enhanced MyCoder v2.2.0...")

        # Stop adaptive mode monitoring
        if hasattr(self.mode_manager, "stop_monitoring"):
            await self.mode_manager.stop_monitoring()

        if self.mcp_bridge:
            try:
                await self.mcp_bridge.close()
            except Exception as exc:
                logger.warning(f"Failed to close MCP bridge: {exc}")
            finally:
                self.mcp_bridge = None
                self.tool_orchestrator = None

        # Clear session store
        self.session_store.clear()

        if self.storage_manager:
            await self.storage_manager.close()

        self._initialized = False
        logger.info("Enhanced MyCoder v2.2.0 shutdown complete")
