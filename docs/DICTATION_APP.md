# Global Dictation App - NativnÃ­ linuxovÃ¡ aplikace pro diktovÃ¡nÃ­

NativnÃ­ aplikace pro globÃ¡lnÃ­ rozpoznÃ¡vÃ¡nÃ­ Å™eÄi v Linuxu, kterÃ¡ umoÅ¾Åˆuje diktovat do libovolnÃ©ho okna vÄetnÄ› terminÃ¡lu.

## ğŸ¯ Vlastnosti

- **GlobÃ¡lnÃ­ funkÄnost** - Funguje ve vÅ¡ech aplikacÃ­ch (prohlÃ­Å¾eÄ, terminÃ¡l, textovÃ½ editor, atd.)
- **Floating GUI** - PÅ™etahovatelnÃ© tlaÄÃ­tko pro rychlÃ½ pÅ™Ã­stup
- **GlobÃ¡lnÃ­ klÃ¡vesovÃ© zkratky** - SpuÅ¡tÄ›nÃ­ diktovÃ¡nÃ­ odkudkoliv
- **Whisper AI** - Podpora OpenAI API i lokÃ¡lnÃ­ch modelÅ¯
- **AutomatickÃ¡ detekce ticha** - UkonÄÃ­ nahrÃ¡vÃ¡nÃ­ po tichu
- **VÃ­cenÃ¡sobnÃ© metody vklÃ¡dÃ¡nÃ­ textu** - xdotool, clipboard
- **KonfigurovatelnÃ©** - JSON konfigurace + environment promÄ›nnÃ©

## ğŸ“¦ Instalace

### 1. Instalace systÃ©movÃ½ch zÃ¡vislostÃ­

```bash
# Ubuntu/Debian
sudo apt-get install xdotool portaudio19-dev python3-pyqt5

# Fedora
sudo dnf install xdotool portaudio-devel python3-qt5

# Arch
sudo pacman -S xdotool portaudio python-pyqt5
```

### 2. Instalace Python balÃ­ÄkÅ¯

```bash
# Instalace vÅ¡ech zÃ¡vislostÃ­ pro speech recognition
poetry install --extras speech

# Nebo jen zÃ¡kladnÃ­ zÃ¡vislosti
pip install sounddevice numpy PyQt5 openai-whisper openai pynput python-xlib pyperclip
```

## ğŸš€ RychlÃ½ start

### SpuÅ¡tÄ›nÃ­ s vÃ½chozÃ­m nastavenÃ­m

```bash
# S OpenAI API (vyÅ¾aduje OPENAI_API_KEY)
export OPENAI_API_KEY="your-api-key"
poetry run dictation run

# S lokÃ¡lnÃ­m Whisper modelem (Å¾Ã¡dnÃ© API, bÄ›Å¾Ã­ offline)
poetry run dictation run --provider local --model base
```

### SpuÅ¡tÄ›nÃ­ s vlastnÃ­m nastavenÃ­m

```bash
# VytvoÅ™it vÃ½chozÃ­ konfiguraci
poetry run dictation config-create

# Upravit konfiguraci
nano ~/.config/mycoder/dictation_config.json

# Spustit s konfiguracÃ­
poetry run dictation run --config ~/.config/mycoder/dictation_config.json
```

## ğŸ® PouÅ¾itÃ­

### GUI reÅ¾im (vÃ½chozÃ­)

1. SpusÅ¥te aplikaci: `poetry run dictation run`
2. ObjevÃ­ se floating tlaÄÃ­tko s mikrofonem ğŸ¤
3. KliknÄ›te na tlaÄÃ­tko nebo stisknÄ›te **Ctrl+Shift+Space**
4. Mluvte (tlaÄÃ­tko se zmÄ›nÃ­ na ÄervenÃ©)
5. PÅ™estaÅˆte mluvit a poÄkejte ~1.5s ticha
6. Text se automaticky vloÅ¾Ã­ do aktivnÃ­ho okna

### KlÃ¡vesovÃ© zkratky

- **Ctrl+Shift+Space** - Zapnout/vypnout nahrÃ¡vÃ¡nÃ­ (vÃ½chozÃ­)
- Lze zmÄ›nit v konfiguraci: `hotkey.combination`

### CLI pÅ™Ã­kazy

```bash
# Spustit aplikaci
dictation run

# Spustit bez GUI (jen klÃ¡vesovÃ© zkratky)
dictation run --no-gui

# Spustit s lokÃ¡lnÃ­m modelem
dictation run --provider local --model base

# Spustit s Äeskou lokalizacÃ­ (vÃ½chozÃ­)
dictation run --language cs

# Spustit s anglickou lokalizacÃ­
dictation run --language en

# Zobrazit konfiguraci
dictation config-show

# VytvoÅ™it vÃ½chozÃ­ konfiguraci
dictation config-create

# Otestovat komponenty
dictation test

# Zobrazit dostupnÃ¡ audio zaÅ™Ã­zenÃ­
dictation devices

# Otestovat vklÃ¡dÃ¡nÃ­ textu
dictation inject "Test text"
```

## âš™ï¸ Konfigurace

### KonfiguraÄnÃ­ soubor

VÃ½chozÃ­ umÃ­stÄ›nÃ­: `~/.config/mycoder/dictation_config.json`

```json
{
  "audio": {
    "sample_rate": 16000,
    "channels": 1,
    "silence_threshold": 0.01,
    "silence_duration": 1.5,
    "max_duration": 60.0
  },
  "whisper": {
    "provider": "api",
    "model": "whisper-1",
    "local_model": "base",
    "language": "cs",
    "temperature": 0.0
  },
  "injection": {
    "method": "auto",
    "typing_delay": 12,
    "use_clipboard_backup": true
  },
  "gui": {
    "enabled": true,
    "button_size": 80,
    "position_x": null,
    "position_y": null
  },
  "hotkey": {
    "enabled": true,
    "combination": ["ctrl", "shift", "space"]
  },
  "log_level": "INFO",
  "log_file": null
}
```

### Environment promÄ›nnÃ©

```bash
# OpenAI API klÃ­Ä
export OPENAI_API_KEY="sk-..."

# Whisper provider (api nebo local)
export DICTATION_WHISPER_PROVIDER="local"

# Jazyk
export DICTATION_LANGUAGE="cs"

# Log ÃºroveÅˆ
export DICTATION_LOG_LEVEL="DEBUG"

# Vypnout GUI
export DICTATION_GUI_ENABLED="false"

# Vypnout hotkeys
export DICTATION_HOTKEY_ENABLED="false"
```

## ğŸ”§ Metody vklÃ¡dÃ¡nÃ­ textu

### `auto` (doporuÄeno)
AutomatickÃ½ vÃ½bÄ›r nejlepÅ¡Ã­ metody podle dostupnÃ½ch nÃ¡strojÅ¯.

### `xdotool_paste`
RychlÃ© vloÅ¾enÃ­ pomocÃ­ Ctrl+V (vyÅ¾aduje xdotool).

### `xdotool_type`
Simulace psanÃ­ jednotlivÃ½ch znakÅ¯ (vyÅ¾aduje xdotool).

### `clipboard_only`
Pouze zkopÃ­ruje do schrÃ¡nky, uÅ¾ivatel musÃ­ ruÄnÄ› vloÅ¾it (Ctrl+V).

## ğŸ™ï¸ Whisper modely

### OpenAI API (`provider: api`)
- **Model**: `whisper-1`
- **VÃ½hody**: VysokÃ¡ pÅ™esnost, rychlÃ¡ odezva
- **NevÃ½hody**: VyÅ¾aduje internet a API klÃ­Ä, nÃ¡klady
- **PouÅ¾itÃ­**: `dictation run --provider api`

### LokÃ¡lnÃ­ modely (`provider: local`)

| Model | Velikost | Rychlost | PÅ™esnost | RAM |
|-------|----------|----------|----------|-----|
| tiny | 39 MB | Velmi rychlÃ¡ | NÃ­zkÃ¡ | ~1 GB |
| base | 74 MB | RychlÃ¡ | DobrÃ¡ | ~1 GB |
| small | 244 MB | StÅ™ednÃ­ | Velmi dobrÃ¡ | ~2 GB |
| medium | 769 MB | PomalÃ¡ | VÃ½bornÃ¡ | ~5 GB |
| large | 1550 MB | Velmi pomalÃ¡ | NejlepÅ¡Ã­ | ~10 GB |

**DoporuÄenÃ­ pro Q9550**:
- Pro rychlou odezvu: `base` nebo `small`
- Pro pÅ™esnost: `medium` (vyÅ¡Å¡Ã­ zÃ¡tÄ›Å¾ CPU)

```bash
# PouÅ¾itÃ­ lokÃ¡lnÃ­ho modelu
dictation run --provider local --model base
```

## ğŸ› Å˜eÅ¡enÃ­ problÃ©mÅ¯

### Audio zaÅ™Ã­zenÃ­ nenalezeno

```bash
# Zobrazit dostupnÃ¡ zaÅ™Ã­zenÃ­
dictation devices

# Otestovat nahrÃ¡vÃ¡nÃ­
python -c "import sounddevice as sd; print(sd.query_devices())"
```

### xdotool nefunguje

```bash
# Instalace xdotool
sudo apt-get install xdotool

# Test
xdotool type "test"
```

### Text se nevklÃ¡dÃ¡

```bash
# Otestovat vklÃ¡dÃ¡nÃ­
dictation inject "Test text"

# Zkusit jinou metodu
dictation run --injection-method clipboard_only
```

### Whisper API chyba

```bash
# Zkontrolovat API klÃ­Ä
echo $OPENAI_API_KEY

# PouÅ¾Ã­t lokÃ¡lnÃ­ model
dictation run --provider local --model base
```

### PyQt5 import error

```bash
# Ubuntu/Debian
sudo apt-get install python3-pyqt5

# Nebo instalace pÅ™es pip
pip install PyQt5
```

## ğŸ—ï¸ Architektura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       GlobalDictationApp                â”‚
â”‚         (Orchestrator)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€ AudioRecorder
           â”‚      â”œâ”€ sounddevice
           â”‚      â””â”€ Silence detection
           â”‚
           â”œâ”€â”€â”€ WhisperTranscriber
           â”‚      â”œâ”€ OpenAI API
           â”‚      â””â”€ Local Whisper
           â”‚
           â”œâ”€â”€â”€ TextInjector
           â”‚      â”œâ”€ xdotool
           â”‚      â””â”€ pyperclip
           â”‚
           â”œâ”€â”€â”€ OverlayButton (PyQt5)
           â”‚      â””â”€ Floating GUI
           â”‚
           â”œâ”€â”€â”€ HotkeyManager (pynput)
           â”‚      â””â”€ Global hotkeys
           â”‚
           â””â”€â”€â”€ ConfigManager
                  â””â”€ JSON config
```

## ğŸ“ PÅ™Ã­klady pouÅ¾itÃ­

### ZÃ¡kladnÃ­ pouÅ¾itÃ­

```python
from speech_recognition import GlobalDictationApp, WhisperProvider

# VytvoÅ™it aplikaci
app = GlobalDictationApp(
    whisper_provider=WhisperProvider.LOCAL,
    whisper_model="base",
    language="cs",
)

# Spustit
app.run()
```

### Bez GUI (jen hotkeys)

```python
app = GlobalDictationApp(
    enable_gui=False,
    enable_hotkeys=True,
    hotkey_combo=["ctrl", "alt", "d"],
)
app.run()
```

### VlastnÃ­ callback

```python
def on_recording_toggle():
    print("Recording toggled!")

app = GlobalDictationApp(enable_gui=False)
# PÅ™idat vlastnÃ­ hotkey
app.hotkey_manager.register_hotkey(
    ["ctrl", "shift", "r"],
    on_recording_toggle
)
app.run()
```

## ğŸ§ª TestovÃ¡nÃ­

```bash
# Otestovat vÅ¡echny komponenty
poetry run dictation test

# Otestovat audio zaÅ™Ã­zenÃ­
poetry run dictation devices

# Otestovat vklÃ¡dÃ¡nÃ­ textu
poetry run dictation inject "Test message"

# Debug reÅ¾im
poetry run dictation run --debug
```

## ğŸ“Š Performance (Q9550 @ 2.83GHz)

| Operace | Whisper API | Whisper Base | Whisper Medium |
|---------|-------------|--------------|----------------|
| NahrÃ¡vÃ¡nÃ­ | Real-time | Real-time | Real-time |
| PÅ™epis (10s audio) | ~1-2s | ~3-5s | ~10-15s |
| VloÅ¾enÃ­ textu | <0.1s | <0.1s | <0.1s |
| **Celkem** | **~2-3s** | **~4-6s** | **~11-16s** |

## ğŸ” BezpeÄnost

- API klÃ­Äe nejsou uklÃ¡dÃ¡ny do konfiguraÄnÃ­ho souboru
- PouÅ¾Ã­vejte environment promÄ›nnÃ© pro citlivÃ© Ãºdaje
- Audio data jsou zpracovÃ¡na lokÃ¡lnÄ› (kromÄ› API pÅ™episÅ¯)
- Å½Ã¡dnÃ¡ telemetrie ani logovÃ¡nÃ­ audio obsahu

## ğŸ› ï¸ VÃ½voj

### Struktura modulÅ¯

```
src/speech_recognition/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ audio_recorder.py        # Audio capture
â”œâ”€â”€ whisper_transcriber.py   # Speech-to-text
â”œâ”€â”€ text_injector.py         # Text injection
â”œâ”€â”€ overlay_button.py        # GUI overlay
â”œâ”€â”€ hotkey_manager.py        # Global hotkeys
â”œâ”€â”€ dictation_app.py         # Main app
â”œâ”€â”€ config.py                # Configuration
â””â”€â”€ cli.py                   # CLI interface
```

### PÅ™idÃ¡nÃ­ vlastnÃ­ho poskytovatele

```python
from speech_recognition import WhisperTranscriber

class CustomTranscriber:
    def transcribe(self, audio_data: bytes) -> str:
        # VlastnÃ­ implementace
        return "transcribed text"
```

## ğŸ“„ Licence

MIT License - viz hlavnÃ­ README projektu

## ğŸ™ PodÄ›kovÃ¡nÃ­

- [OpenAI Whisper](https://github.com/openai/whisper) - Speech recognition
- [PyQt5](https://www.riverbankcomputing.com/software/pyqt/) - GUI framework
- [sounddevice](https://python-sounddevice.readthedocs.io/) - Audio I/O
- [pynput](https://pynput.readthedocs.io/) - Global hotkeys
- [xdotool](https://github.com/jordansissel/xdotool) - X11 automation
