# Kapitola 7: Hardware Strategie pro ML/LLM

## Ãšvod

MÃ¡te stack rÅ¯znÃ©ho hardware - Raspberry Pi, starÃ½ PC s Q9550, moÅ¾nÃ¡ PS4, moÅ¾nÃ¡ Xbox. Jak to vÅ¡echno efektivnÄ› vyuÅ¾Ã­t pro Machine Learning a LLM inference? V tÃ©to kapitole sestavÃ­me praktickÃ© strategie pro rÅ¯znÃ© scÃ©nÃ¡Å™e a budgety.

---

## Hardware Inventory - Co mÃ¡me k dispozici?

### TypickÃ½ home lab setup

```
DostupnÃ½ hardware:
â”œâ”€ Desktop PC (Q9550 @ 2.83GHz, 8GB RAM)
â”‚  â””â”€ Pros: 4 jÃ¡dra, sluÅ¡nÃ½ vÃ½kon, low cost electricity
â”‚
â”œâ”€ Raspberry Pi 3B (1GB RAM)
â”‚  â””â”€ Pros: 5W spotÅ™eba, always-on capable
â”‚
â”œâ”€ Raspberry Pi 4 (4GB RAM)
â”‚  â””â”€ Pros: 4Ã— Cortex-A72, USB 3.0, Gigabit Ethernet
â”‚
â”œâ”€ PlayStation 4 (8-core Jaguar, 8GB GDDR5)
â”‚  â””â”€ Pros: LevnÃ½ (used), decent CPU
â”‚
â”œâ”€ Xbox One (8-core Jaguar, 8GB DDR3)
â”‚  â””â”€ Pros: Velmi levnÃ½ (used), dev mode
â”‚
â””â”€ MoÅ¾nÃ½ upgrade: GPU (RTX 3060, RX 6600, atd.)
   â””â”€ Pros: MASSIVE performance boost pro ML
```

---

## Use Case #1: Personal AI Assistant (MyCoder-v2.0)

### CÃ­l
BÄ›Å¾Ã­cÃ­ AI assistant s multi-provider fallback, dostupnÃ½ 24/7, low cost.

### OptimÃ¡lnÃ­ setup

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Main Server: Q9550 Desktop PC          â”‚
â”‚                                         â”‚
â”‚ â”œâ”€ MyCoder-v2.0 API (Flask/FastAPI)    â”‚
â”‚ â”œâ”€ Provider Router                      â”‚
â”‚ â”‚  â”œâ”€ Claude API (primary)             â”‚
â”‚ â”‚  â”œâ”€ Gemini API (fallback)            â”‚
â”‚ â”‚  â””â”€ Ollama Local (offline fallback)  â”‚
â”‚ â”œâ”€ Ollama Server (Phi-3 Mini)          â”‚
â”‚ â”œâ”€ PostgreSQL (conversation history)   â”‚
â”‚ â””â”€ Redis (cache)                        â”‚
â”‚                                         â”‚
â”‚ Performance:                            â”‚
â”‚ - API queries: <500ms                   â”‚
â”‚ - Ollama inference: ~30 tokens/s        â”‚
â”‚ - Power: ~95W                           â”‚
â”‚ - Uptime: 24/7                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“ HTTP API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Raspberry Pi 4: Dashboard Terminal      â”‚
â”‚                                         â”‚
â”‚ â”œâ”€ 7" Touchscreen display              â”‚
â”‚ â”œâ”€ Voice input (Whisper API)           â”‚
â”‚ â”œâ”€ TTS output                           â”‚
â”‚ â””â”€ Web UI (React/Vue)                   â”‚
â”‚                                         â”‚
â”‚ Power: ~5W                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†“ Sync
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mobile: Android App                     â”‚
â”‚                                         â”‚
â”‚ â”œâ”€ Voice dictation (local STT)         â”‚
â”‚ â”œâ”€ Text-to-Speech (local TTS)          â”‚
â”‚ â”œâ”€ Offline mode (Android SpeechRec)    â”‚
â”‚ â””â”€ Sync with server (when online)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ProÄ tento setup:**

1. **Q9550 jako main server:**
   - âœ… Dost vÃ½konu pro Phi-3 Mini (CPU only)
   - âœ… Lze bÄ›Å¾et 24/7 (~$10-15/mÄ›sÃ­c elektÅ™ina)
   - âœ… Thermal management uÅ¾ implementovÃ¡no
   - âœ… Fallback kdyÅ¾ cloud API failne

2. **RPi 4 jako terminal:**
   - âœ… Low power (always-on displej = $1/mÄ›sÃ­c)
   - âœ… Dedicated UI (nezdrÅ¾uje main server)
   - âœ… Voice interface
   - âœ… Offload inference na server

3. **Mobile app:**
   - âœ… Portable
   - âœ… Offline capable
   - âœ… Best UX (uÅ¾ implementovÃ¡no!)

**Cost breakdown:**
- Hardware: $0 (uÅ¾ mÃ¡te)
- Electricity: ~$15/mÄ›sÃ­c (Q9550 + RPi 4)
- Cloud API: ~$10-30/mÄ›sÃ­c (Claude/Gemini jako primary)
- **Total: $25-45/mÄ›sÃ­c**

---

## Use Case #2: Budget ML Learning Lab

### CÃ­l
Setup pro learning ML/LLM development, experimenty, prototyping.

### OptimÃ¡lnÃ­ setup

**Option A: CPU-only (no budget)**

```
Raspberry Pi 4 (4GB) - $55
â”œâ”€ OS: Raspberry Pi OS (64-bit)
â”œâ”€ Python 3.11
â”œâ”€ PyTorch (CPU-only build)
â”œâ”€ Transformers library
â”œâ”€ TinyLlama 1.1B (quantized 4-bit)
â””â”€ Jupyter Notebook (remote access)

Capabilities:
- âœ… Train tiny models (<100M params)
- âœ… Fine-tune TinyLlama (slow but possible)
- âœ… Inference small models (1-2 tok/s)
- âœ… Learn ML concepts
- âŒ Train anything serious
```

**Hands-on projects:**
```python
# Project 1: Sentiment classifier
from transformers import pipeline
classifier = pipeline("sentiment-analysis", model="distilbert-base-uncased")
result = classifier("I love machine learning!")

# Project 2: Text generation
from transformers import AutoTokenizer, AutoModelForCausalLM
model = AutoModelForCausalLM.from_pretrained("TinyLlama/TinyLlama-1.1B-Chat-v1.0")
# ... inference code

# Project 3: Fine-tuning
from transformers import TrainingArguments, Trainer
# Fine-tune on custom dataset (takes hours, but works!)
```

**Option B: Used GPU ($200 budget)**

```
Shopping list:
â”œâ”€ Used GTX 1660 Super (6GB VRAM) - $120
â”œâ”€ Or: Used RX 580 (8GB VRAM) - $100
â””â”€ Install in Q9550 PC

Capabilities:
- âœ… Train medium models (up to 1B params)
- âœ… Fine-tune Phi-3 Mini (moÅ¾nÃ©!)
- âœ… Inference: 40-60 tok/s (Phi-3)
- âœ… Run Stable Diffusion
- âœ… Learn CUDA/ROCm programming
```

**Why used GPU is worth it:**
```
CPU-only inference:    2-3 tok/s
GPU inference:         40-60 tok/s
Speedup:              20x faster!

Training time:
CPU: 48 hours
GPU: 2-3 hours
Speedup:              16-24x faster!
```

**Option C: Cloud GPU (pay-per-use)**

```
Providers:
â”œâ”€ Google Colab (Free tier)
â”‚  â”œâ”€ Tesla T4 (free, limited time)
â”‚  â”œâ”€ 12GB RAM
â”‚  â””â”€ Good for learning
â”‚
â”œâ”€ Kaggle Notebooks (Free)
â”‚  â”œâ”€ Tesla P100 (free!)
â”‚  â”œâ”€ 16GB RAM
â”‚  â””â”€ 30h/week limit
â”‚
â”œâ”€ Paperspace Gradient (Free + paid)
â”‚  â”œâ”€ Free: M4000 (8GB)
â”‚  â”œâ”€ Paid: A4000, A100, atd.
â”‚  â””â”€ $0.45/hour (A4000)
â”‚
â””â”€ Vast.ai (cheapest)
   â”œâ”€ Rent GPUs from individuals
   â”œâ”€ RTX 3090: ~$0.30/hour
   â””â”€ Good for heavy training
```

**DoporuÄenÃ­:**
- **Learning:** Colab/Kaggle free tier (nepotÅ™ebujete vlastnÃ­ HW)
- **Prototyping:** Raspberry Pi 4 (hands-on, vÅ¾dy dostupnÃ©)
- **Serious work:** Used GPU (best long-term value)

---

## Use Case #3: Home Media + Voice Assistant

### CÃ­l
Kombinace media center + AI assistant + smart home hub.

### Setup

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Raspberry Pi 4 (4GB)                    â”‚
â”‚ Connected to TV (HDMI)                  â”‚
â”‚                                         â”‚
â”‚ Services:                               â”‚
â”‚ â”œâ”€ Kodi (media center)                  â”‚
â”‚ â”œâ”€ Home Assistant (smart home)         â”‚
â”‚ â”œâ”€ Voice assistant (Whisper + Ollama)  â”‚
â”‚ â”œâ”€ TTS engine                           â”‚
â”‚ â””â”€ Web dashboard                        â”‚
â”‚                                         â”‚
â”‚ Workflow:                               â”‚
â”‚ "Hey Pi, play Breaking Bad"             â”‚
â”‚   â†’ Whisper STT (offload na server)     â”‚
â”‚   â†’ LLM parse intent (Phi-3)            â”‚
â”‚   â†’ Kodi API call                       â”‚
â”‚   â†’ TV starts playing                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†‘ Offload heavy tasks
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Q9550 Server (background)               â”‚
â”‚                                         â”‚
â”‚ â”œâ”€ Whisper.cpp (STT server)            â”‚
â”‚ â”œâ”€ Ollama (Phi-3 Mini)                 â”‚
â”‚ â””â”€ API endpoints                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation:**

```python
# voice_assistant.py na RPi 4
import requests
import subprocess
import pyttsx3

def record_audio():
    """Record audio from USB mic"""
    subprocess.run(['arecord', '-d', '5', '-f', 'S16_LE', '-r', '16000', 'query.wav'])

def transcribe(audio_file):
    """Send to Whisper server"""
    with open(audio_file, 'rb') as f:
        response = requests.post('http://q9550-server:8080/whisper', files={'file': f})
    return response.json()['text']

def query_llm(text):
    """Send to Ollama server"""
    response = requests.post('http://q9550-server:11434/api/generate', json={
        'model': 'phi3:mini',
        'prompt': f'Parse this voice command and return JSON: {text}'
    })
    return response.json()

def execute_command(intent):
    """Execute based on parsed intent"""
    if intent['action'] == 'play':
        # Call Kodi API
        requests.post('http://localhost:8080/jsonrpc', json={
            'method': 'Player.Open',
            'params': {'item': {'title': intent['media']}}
        })

def speak(text):
    """Text-to-Speech"""
    engine = pyttsx3.init()
    engine.say(text)
    engine.runAndWait()

# Main loop
while True:
    wait_for_wake_word()  # "Hey Pi"
    record_audio()
    text = transcribe('query.wav')
    intent = query_llm(text)
    execute_command(intent)
    speak("Done!")
```

**ProÄ tento setup:**
- âœ… RPi 4 = tichÃ½, low power, always-on
- âœ… Q9550 = heavy lifting (Whisper, LLM)
- âœ… Distributed = kaÅ¾dÃ½ dÄ›lÃ¡ co umÃ­ nejlÃ©pe
- âœ… Cost effective (~$10/mÄ›sÃ­c elektÅ™ina)

---

## Use Case #4: Gaming Console Repurposing

### MÅ¯Å¾eme pouÅ¾Ã­t PS4/Xbox pro ML?

**Short answer: Technicky ano, prakticky ne.**

### PS4 Pro jako ML box

**Hardware:**
- CPU: 8Ã— 2.1 GHz Jaguar
- RAM: 8 GB GDDR5
- GPU: 4.2 TFLOPS (ALE bez Linux driveru = useless)

**Pokud Linux + CPU-only:**

```bash
# Instalace Ollama na PS4 Linux
curl -fsSL https://ollama.com/install.sh | sh
ollama pull tinyllama  # Phi-3 = pÅ™Ã­liÅ¡ velkÃ½ pro 7GB RAM

# Benchmark
time ollama run tinyllama "Hello world"
# Result: 0.8-1.2 tok/s (VELMI pomalÃ©)
```

**SrovnÃ¡nÃ­:**

| Hardware | Tokens/s | Power | Cost (used) |
|----------|----------|-------|-------------|
| PS4 Pro (CPU) | 1.0 | 120W | $200 |
| Q9550 (CPU) | 30 | 95W | $50 |
| RPi 4 (CPU) | 2.5 | 5W | $55 |
| RTX 3060 (GPU) | 100 | 170W | $250 |

**Verdict:**
- âŒ PS4 Pro je HORÅ Ã neÅ¾ Q9550
- âŒ VÃ­ce power consumption
- âŒ HluÄnÄ›jÅ¡Ã­ (fan noise)
- âŒ SloÅ¾itÄ›jÅ¡Ã­ setup (Linux install)
- âœ… JedinÃ¡ vÃ½hoda: GDDR5 RAM (ale nevyuÅ¾itÃ¡ bez GPU)

**DoporuÄenÃ­:** **NE**, nepouÅ¾Ã­vat PS4 pro ML. LepÅ¡Ã­ pouÅ¾Ã­t bÄ›Å¾nÃ½ PC nebo RPi 4.

---

### Xbox One (Developer Mode) jako ML box

**Developer Mode moÅ¾nosti:**

```csharp
// UWP app - C# ML.NET
using Microsoft.ML;

var mlContext = new MLContext();
var model = mlContext.Model.Load("model.zip", out var schema);
var predictions = model.Transform(testData);

// ALE: Performance throttled, max 2GB RAM, no GPU access
```

**Benchmark (TinyLlama via Python UWP app):**
- Tokens/s: 0.5-0.8 (NEJPOMALEJÅ Ã!)
- RAM limit: 2 GB (system kills app nad limitem)
- No GPU: Jen CPU
- Noise: ğŸ”ŠğŸ”ŠğŸ”Š (fan 100%)

**Verdict:** âŒ JeÅ¡tÄ› horÅ¡Ã­ neÅ¾ PS4. Totally impractical.

---

## Use Case #5: NAS + ML Combo Server

### CÃ­l
CentrÃ¡lnÃ­ server pro storage + ML inference + home automation.

### Hardware

```
Shopping list (used market):
â”œâ”€ Dell Optiplex 7050 (i5-7500, 16GB RAM) - $150
â”œâ”€ 2Ã— 4TB HDD (RAID 1 mirror) - $120
â”œâ”€ Used GTX 1660 Super (6GB VRAM) - $120
â””â”€ Total: ~$390

Nebo DIY build:
â”œâ”€ Ryzen 5 3600 (6-core) - $100 used
â”œâ”€ 16GB DDR4 RAM - $40 used
â”œâ”€ B450 motherboard - $60 used
â”œâ”€ 2Ã— 4TB HDD - $120
â”œâ”€ Used GPU (optional) - $120
â””â”€ Total: ~$440
```

### Services Stack

```yaml
# docker-compose.yml
version: '3.8'

services:
  # NAS - File sharing
  samba:
    image: dperson/samba
    ports:
      - "445:445"
    volumes:
      - /mnt/storage:/share

  # ML - Ollama server
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

  # ML - Whisper API
  whisper:
    image: onerahmet/openai-whisper-asr-webservice
    ports:
      - "9000:9000"
    environment:
      - ASR_MODEL=base
      - ASR_ENGINE=faster_whisper

  # Home Automation
  homeassistant:
    image: homeassistant/home-assistant
    ports:
      - "8123:8123"
    volumes:
      - ha_config:/config

  # Dashboard
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"

  # Database
  postgres:
    image: postgres:15
    volumes:
      - pg_data:/var/lib/postgresql/data

volumes:
  ollama_data:
  ha_config:
  pg_data:
```

**Capabilities:**
- âœ… 8TB storage (RAID 1)
- âœ… ML inference (Phi-3, Whisper)
- âœ… Home automation hub
- âœ… Monitoring (Grafana)
- âœ… Database server
- âœ… 24/7 uptime
- âœ… Low noise (tower case + Noctua fans)

**Power consumption:**
- Idle: 40W
- Load: 120W (s GPU)
- Cost: ~$15-20/mÄ›sÃ­c

---

## Cost-Benefit Analysis

### Scenario 1: Pure Cloud (no local hardware)

```
Monthly costs:
â”œâ”€ ChatGPT Plus (GPT-4): $20
â”œâ”€ Claude Pro: $20
â”œâ”€ Google Colab Pro: $10
â”œâ”€ Whisper API (1h/day): $6
â””â”€ Total: $56/mÄ›sÃ­c = $672/rok

Pros:
âœ… Zero upfront cost
âœ… Zero maintenance
âœ… Always latest models
âœ… Unlimited scaling

Cons:
âŒ Vendor lock-in
âŒ No privacy (data v cloudu)
âŒ Offline = nefunguje
âŒ Cumulative cost (3 roky = $2000+)
```

---

### Scenario 2: Hybrid (cloud + local)

```
Upfront:
â”œâ”€ Q9550 PC: $50 (uÅ¾ mÃ¡te)
â”œâ”€ Used GPU (GTX 1660S): $120
â””â”€ Total: $170

Monthly:
â”œâ”€ Electricity (Q9550 + GPU): $18
â”œâ”€ Claude API (occasional): $5
â””â”€ Total: $23/mÄ›sÃ­c = $276/rok

Year 1: $170 + $276 = $446
Year 2: $276
Year 3: $276
3-year total: $998

Pros:
âœ… Privacy (local inference)
âœ… Offline capable
âœ… Own your setup
âœ… Learning opportunities
âœ… Cheaper long-term (3 roky)

Cons:
âš ï¸ Maintenance required
âš ï¸ Upfront cost
âš ï¸ Local models < GPT-4 quality
```

**Break-even point:** 18 mÄ›sÃ­cÅ¯

---

### Scenario 3: Pure Local (full DIY)

```
Upfront:
â”œâ”€ Used workstation: $300
â”œâ”€ Used GPU (RTX 3060): $250
â”œâ”€ 32GB RAM upgrade: $80
â””â”€ Total: $630

Monthly:
â”œâ”€ Electricity (150W avg): $22
â””â”€ Total: $22/mÄ›sÃ­c = $264/rok

Year 1: $630 + $264 = $894
Year 2: $264
Year 3: $264
3-year total: $1422

Pros:
âœ… 100% privacy
âœ… Fully offline
âœ… Best performance/$ long-term
âœ… No vendor lock-in
âœ… Resale value (HW mÃ¡ value)

Cons:
âŒ Highest upfront cost
âŒ Most maintenance
âŒ Local models â‰  GPT-4
âŒ Requires technical skills
```

**Break-even vs cloud:** 2 roky

**Break-even vs hybrid:** Never (ale benefits jsou greater)

---

## DoporuÄenÃ­ pro rÅ¯znÃ© profily

### 1. Casual User (obÄasnÃ© pouÅ¾itÃ­)

**Profil:**
- PouÅ¾Ã­vÃ¡ AI 1-2x tÃ½dnÄ›
- HlavnÄ› simple queries
- NepotÅ™ebuje privacy
- Technicky ne-savvy

**DoporuÄenÃ­:**
```
â†’ ChatGPT Free tier
â†’ Claude.ai Free tier
â†’ Google Gemini Free

Cost: $0/mÄ›sÃ­c
Effort: Minimal
```

---

### 2. Power User (dennÃ­ pouÅ¾itÃ­)

**Profil:**
- PouÅ¾Ã­vÃ¡ AI kaÅ¾dÃ½ den
- Coding, writing, research
- Chce best quality
- Budget $20-50/mÄ›sÃ­c OK

**DoporuÄenÃ­:**
```
â†’ ChatGPT Plus ($20)
â†’ Nebo Claude Pro ($20)
â†’ Plus: Local Ollama (fallback)

Setup:
â”œâ”€ Cloud pro critical work
â””â”€ Local pro experimenty

Cost: $20-25/mÄ›sÃ­c
```

---

### 3. Developer/Tinkerer (learning ML)

**Profil:**
- Chce se nauÄit ML/LLM
- Experimentuje s modely
- Budget hardware OK
- Technical skills âœ…

**DoporuÄenÃ­:**
```
â†’ Raspberry Pi 4 nebo used PC
â†’ + Used GPU ($100-200)
â†’ Self-hosted Ollama
â†’ Cloud pouze for heavy training

Setup:
â”œâ”€ Local: Learning, prototyping
â”œâ”€ Colab/Kaggle: Heavy training
â””â”€ Prod: Hybrid (local + API fallback)

Upfront: $200-400
Monthly: $15-20
```

---

### 4. Privacy-Conscious (data security)

**Profil:**
- NepÅ¯jÄÃ­ data cloud providers
- Legal/medical/sensitive work
- Budget nenÃ­ limit
- Technical capable

**DoporuÄenÃ­:**
```
â†’ Full self-hosted stack
â†’ Workstation + GPU
â†’ Air-gapped moÅ¾nÃ©
â†’ Zero cloud dependency

Hardware:
â”œâ”€ Workstation: $300-500
â”œâ”€ GPU (RTX 3060 Ti): $300
â”œâ”€ Storage: $100-200
â””â”€ Total: $700-1000

Monthly: $20-30 (elektÅ™ina)
```

---

### 5. Enthusiast/Home Lab

**Profil:**
- BavÃ­ ho tech projekty
- Chce comprehensive setup
- Budget: flexible
- Skill: expert

**DoporuÄenÃ­:**
```
â†’ Full home lab setup
â†’ NAS + ML + automation
â†’ Multiple services
â†’ Raspberry Pi cluster (moÅ¾nÃ¡)

Hardware:
â”œâ”€ Main server (Ryzen + GPU): $600
â”œâ”€ NAS drives: $200
â”œâ”€ RPi 4 (dashboard): $55
â”œâ”€ Network upgrades: $100
â””â”€ Total: ~$1000

Monthly: $30-40

Benefits:
âœ… Complete control
âœ… Learning platform
âœ… Bragging rights ğŸ˜„
```

---

## Raspberry Pi Cluster - Je to worth it?

### Concept

```
4Ã— Raspberry Pi 4 (4GB) Cluster
â”œâ”€ Kubernetes (K3s)
â”œâ”€ Load balanced services
â”œâ”€ Distributed ML training (moÅ¾nÃ¡?)
â””â”€ Cost: 4 Ã— $55 = $220

Vs.

1Ã— Used Workstation
â”œâ”€ i5-6500 (4-core @ 3.2GHz)
â”œâ”€ 16GB RAM
â”œâ”€ PodobnÃ½ CPU power
â””â”€ Cost: $150
```

**Benchmark comparison:**

| Task | 4Ã— RPi 4 | i5 Workstation |
|------|----------|----------------|
| Ollama (Phi-3) | 8-10 tok/s | 25-30 tok/s |
| Whisper (base) | 2x realtime | 8x realtime |
| Docker services | Good | Better |
| Power | 20W | 65W |
| **Cost** | **$220** | **$150** |

**Verdict:**
- âŒ RPi cluster: Cool project, ALE worse value/$
- âœ… Workstation: Better performance/cost
- âœ… RPi cluster IF: Learning Kubernetes, distributed systems

**DÅ¯vod proÄ cluster:**
- Learning platform (Kubernetes, Docker Swarm)
- Fun project (looks cool!)
- Redundancy (1 node fail = cluster runs)

**DÅ¯vod proÄ NE cluster:**
- Worse performance/$
- More complexity
- ARM architecture (some software incompatible)

---

## Final Recommendations

### Optimal Setups (2025)

**Budget Tier ($0-100):**
```
Hardware:
â”œâ”€ Raspberry Pi 4 (4GB) - $55
â”œâ”€ Or: Used thin client - $50-80
â””â”€ Or: Cloud free tiers - $0

Use: Learning, light inference, dashboard
Performance: 2-3 tok/s (CPU only)
```

**Value Tier ($100-300):**
```
Hardware:
â”œâ”€ Used PC (i5 gen 6-7) - $100-150
â”œâ”€ + Used GPU (GTX 1660/RX 580) - $100-120
â””â”€ Total: $200-270

Use: Serious ML work, training, inference
Performance: 40-60 tok/s
Best bang-for-buck!
```

**Enthusiast Tier ($300-600):**
```
Hardware:
â”œâ”€ Workstation (Ryzen 5 5600) - $200
â”œâ”€ 32GB RAM - $80
â”œâ”€ RTX 3060 (12GB) - $280
â”œâ”€ NVMe SSD - $40
â””â”€ Total: $600

Use: Full home lab, NAS, automation
Performance: 80-100 tok/s
Future-proof
```

**Pro Tier ($600+):**
```
Hardware:
â”œâ”€ Ryzen 7 5800X3D - $300
â”œâ”€ 64GB RAM - $160
â”œâ”€ RTX 4070 Ti nebo RX 7900 XT - $600-700
â”œâ”€ Enterprise NVMe - $100
â””â”€ Total: $1160+

Use: Production workloads, business
Performance: 120-150 tok/s
Commercial viable
```

---

## ZÃ¡vÄ›r

**Key Takeaways:**

1. **Don't buy PS4/Xbox for ML** - Worse than used PCs
2. **Used GPU = best upgrade** - 20-30x speedup
3. **Cloud has place** - Prototyping, occasional heavy tasks
4. **Hybrid approach wins** - Local + cloud fallback
5. **Raspberry Pi** - Great for dashboards, not for ML
6. **Q9550 is OK** - For CPU inference, but upgrade path exists

**Golden rule:**
> "Right tool for right job. Mix and match based on your use case."

**My personal setup:**
```
â”œâ”€ Q9550 server (MyCoder API + Ollama)
â”œâ”€ RPi 4 (dashboard + voice terminal)
â”œâ”€ Android phone (mobile client)
â”œâ”€ Cloud APIs (critical tasks)
â””â”€ Future: Used RTX 3060 ($250)
```

**Total cost:** ~$350 hardware + $20/mÄ›sÃ­c

**Result:** Full-featured AI assistant, self-hosted, privacy-respecting, offline-capable. ğŸ‰

---

**Konec knihy!** ğŸ“š

DoufÃ¡m Å¾e tyto poznÃ¡mky byly uÅ¾iteÄnÃ©. Happy hacking! ğŸ”§ğŸ¤–

---

**Appendix: DalÅ¡Ã­ zdroje**

- **Hardware:**
  - r/homelab (Reddit community)
  - r/selfhosted (self-hosting resources)
  - ServeTheHome (server hardware reviews)

- **Software:**
  - Ollama: https://ollama.com
  - Whisper.cpp: https://github.com/ggerganov/whisper.cpp
  - HuggingFace: https://huggingface.co

- **Learning:**
  - Fast.ai (free ML course)
  - Andrej Karpathy's lectures
  - Papers With Code

**Stay curious. Keep learning. Fight corporate svinÃ¡rny.** ğŸš€
